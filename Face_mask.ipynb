{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the images\n",
    "imagePaths = list(paths.list_images('dataset'))\n",
    "data = []\n",
    "labels = []\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "\t# extract the class label from the filename\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\t# load the input image (224x224) and preprocess it\n",
    "\timage = load_img(imagePath, target_size=(224, 224))\n",
    "\timage = img_to_array(image)\n",
    "\timage = preprocess_input(image)\n",
    "\t# update the data and labels lists, respectively\n",
    "\tdata.append(image)\n",
    "\tlabels.append(label)\n",
    "# convert the data and labels to NumPy arrays\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\JOEMATHEWS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# using mobinetv2 pre trained model\n",
    "\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_shape=(224, 224, 3))\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding \n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.20, stratify=labels, random_state=42)\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training head...\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\JOEMATHEWS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "95/95 [==============================] - 34s 357ms/step - loss: 0.5733 - acc: 0.7080 - val_loss: 0.4506 - val_acc: 0.8031\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 30s 319ms/step - loss: 0.2980 - acc: 0.8827 - val_loss: 0.3782 - val_acc: 0.8383\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 32s 337ms/step - loss: 0.2352 - acc: 0.9107 - val_loss: 0.2861 - val_acc: 0.8774\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 35s 366ms/step - loss: 0.1902 - acc: 0.9344 - val_loss: 0.3338 - val_acc: 0.8644\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 31s 331ms/step - loss: 0.1699 - acc: 0.9380 - val_loss: 0.2947 - val_acc: 0.8866\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 31s 325ms/step - loss: 0.1584 - acc: 0.9413 - val_loss: 0.3304 - val_acc: 0.8761\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 30s 312ms/step - loss: 0.1594 - acc: 0.9374 - val_loss: 0.2638 - val_acc: 0.9009\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 28s 293ms/step - loss: 0.1238 - acc: 0.9558 - val_loss: 0.3035 - val_acc: 0.8905\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 29s 309ms/step - loss: 0.1318 - acc: 0.9499 - val_loss: 0.4025 - val_acc: 0.8644\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 0.1154 - acc: 0.9568 - val_loss: 0.3176 - val_acc: 0.8879\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 28s 300ms/step - loss: 0.1168 - acc: 0.9572 - val_loss: 0.3185 - val_acc: 0.8957\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 29s 308ms/step - loss: 0.1092 - acc: 0.9628 - val_loss: 0.3714 - val_acc: 0.8774\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 0.0963 - acc: 0.9693 - val_loss: 0.2864 - val_acc: 0.9009\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 0.1103 - acc: 0.9595 - val_loss: 0.1798 - val_acc: 0.9270\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 0.0996 - acc: 0.9637 - val_loss: 0.2651 - val_acc: 0.9048\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 29s 309ms/step - loss: 0.0982 - acc: 0.9609 - val_loss: 0.3305 - val_acc: 0.8879\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 0.0902 - acc: 0.9699 - val_loss: 0.3191 - val_acc: 0.8957\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 28s 298ms/step - loss: 0.0838 - acc: 0.9710 - val_loss: 0.2835 - val_acc: 0.9022\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 32s 335ms/step - loss: 0.0922 - acc: 0.9674 - val_loss: 0.2990 - val_acc: 0.8970\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 30s 313ms/step - loss: 0.0987 - acc: 0.9631 - val_loss: 0.2539 - val_acc: 0.9074\n"
     ]
    }
   ],
   "source": [
    "# training our model\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BS,\n",
    "\tepochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"face_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"face_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To save the trained model\n",
    "model.save('mask_recog_ver2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\JOEMATHEWS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\JOEMATHEWS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\JOEMATHEWS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\JOEMATHEWS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\JOEMATHEWS\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "cascPath = os.path.dirname(\n",
    "    cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "model = load_model(\"mask_recog_ver2.h5\")\n",
    "\n",
    "video_capture = cv2.VideoCapture(\"Test1.mp4\")\n",
    "\n",
    "# def rescale_frame(frame, percent=75):\n",
    "#     width = int(frame.shape[1] * percent/ 100)\n",
    "#     height = int(frame.shape[0] * percent/ 100)\n",
    "#     dim = (width, height)\n",
    "#     return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=5,\n",
    "                                         minSize=(60, 60),\n",
    "                                         flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    faces_list=[]\n",
    "    preds=[]\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_frame = frame[y:y+h,x:x+w]\n",
    "        face_frame = cv2.cvtColor(face_frame, cv2.COLOR_BGR2RGB)\n",
    "        face_frame = cv2.resize(face_frame, (224, 224))\n",
    "        face_frame = img_to_array(face_frame)\n",
    "        face_frame = np.expand_dims(face_frame, axis=0)\n",
    "        face_frame =  preprocess_input(face_frame)\n",
    "        faces_list.append(face_frame)\n",
    "        if len(faces_list)>0:\n",
    "            preds = model.predict(faces_list)\n",
    "        for pred in preds:\n",
    "            (mask, withoutMask) = pred\n",
    "        label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "        color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "        cv2.putText(frame, label, (x, y- 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h),color, 2)\n",
    "        # Display the resulting frame\n",
    "    #frame75 = rescale_frame(frame, percent=25)\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
