{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEoncLMkHU-B"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
    "from keras.optimizers import RMSprop\n",
    "import pickle\n",
    "import sys\n",
    "import heapq\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "kFSpPBY43Tgr",
    "outputId": "a5a214b0-e753-4d1d-b608-b1ee3643cb1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "# find the total length \n",
    "path = 'nietzsche.txt'\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "8ecMqSfZ3Tei",
    "outputId": "62deccb5-a6ff-4751-d7a7-0b8a4c0e390a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique chars: 57\n"
     ]
    }
   ],
   "source": [
    "# unique characters\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "print(f'unique chars: {len(chars)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "0_q2M_i23TcE",
    "outputId": "4047964f-b46c-49b5-c07d-7a9aecdded42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num training examples: 200285\n"
     ]
    }
   ],
   "source": [
    "# splitting into sequences of 40 characters\n",
    "SEQUENCE_LENGTH = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - SEQUENCE_LENGTH, step):\n",
    "    sentences.append(text[i: i + SEQUENCE_LENGTH])\n",
    "    next_chars.append(text[i + SEQUENCE_LENGTH])\n",
    "print(f'num training examples: {len(sentences)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7OInws93vgH"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6K-jkSEs3vdU",
    "outputId": "44876b35-c309-45e2-ef05-eeac6e318780"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'ve been unskilled and unseemly methods f'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cx1mLT4I3vax",
    "outputId": "057e9fbd-5edb-4a2f-fa82-6605473a385b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "Ty-CUpFA3vX6",
    "outputId": "f21efda8-5b78-492f-8d3a-5180be354bf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False]),\n",
       " array([False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False]))"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0],y[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "t9O0iN2z3TZg",
    "outputId": "ba5c6273-e5d5-46fd-d70b-8b6a9d34aa82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200285, 40, 57), (200285, 57))"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8XSowPNKmAF"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=False,input_shape=(SEQUENCE_LENGTH, len(chars))))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "jnmQqxoCnnol",
    "outputId": "edec0fdd-4af1-4fd3-f0ad-4b832b37c010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1487/1487 [==============================] - 179s 121ms/step - loss: 1.9868 - accuracy: 0.4181 - val_loss: 1.6705 - val_accuracy: 0.4984\n",
      "Epoch 2/20\n",
      "1487/1487 [==============================] - 181s 122ms/step - loss: 1.6266 - accuracy: 0.5162 - val_loss: 1.5685 - val_accuracy: 0.5284\n",
      "Epoch 3/20\n",
      "1487/1487 [==============================] - 177s 119ms/step - loss: 1.5371 - accuracy: 0.5404 - val_loss: 1.5313 - val_accuracy: 0.5388\n",
      "Epoch 4/20\n",
      "1487/1487 [==============================] - 185s 125ms/step - loss: 1.4893 - accuracy: 0.5542 - val_loss: 1.5284 - val_accuracy: 0.5373\n",
      "Epoch 5/20\n",
      "1487/1487 [==============================] - 179s 121ms/step - loss: 1.4599 - accuracy: 0.5613 - val_loss: 1.5001 - val_accuracy: 0.5444\n",
      "Epoch 6/20\n",
      "1487/1487 [==============================] - 179s 120ms/step - loss: 1.4356 - accuracy: 0.5676 - val_loss: 1.4964 - val_accuracy: 0.5474\n",
      "Epoch 7/20\n",
      "1487/1487 [==============================] - 181s 122ms/step - loss: 1.4177 - accuracy: 0.5727 - val_loss: 1.4929 - val_accuracy: 0.5527\n",
      "Epoch 8/20\n",
      "1487/1487 [==============================] - 182s 122ms/step - loss: 1.4024 - accuracy: 0.5755 - val_loss: 1.4857 - val_accuracy: 0.5509\n",
      "Epoch 9/20\n",
      "1487/1487 [==============================] - 182s 122ms/step - loss: 1.3893 - accuracy: 0.5794 - val_loss: 1.4746 - val_accuracy: 0.5573\n",
      "Epoch 10/20\n",
      "1487/1487 [==============================] - 178s 120ms/step - loss: 1.3774 - accuracy: 0.5822 - val_loss: 1.4797 - val_accuracy: 0.5540\n",
      "Epoch 11/20\n",
      "1487/1487 [==============================] - 182s 122ms/step - loss: 1.3690 - accuracy: 0.5848 - val_loss: 1.4854 - val_accuracy: 0.5565\n",
      "Epoch 12/20\n",
      "1487/1487 [==============================] - 180s 121ms/step - loss: 1.3602 - accuracy: 0.5861 - val_loss: 1.4878 - val_accuracy: 0.5531\n",
      "Epoch 13/20\n",
      "1487/1487 [==============================] - 182s 122ms/step - loss: 1.3528 - accuracy: 0.5888 - val_loss: 1.4843 - val_accuracy: 0.5571\n",
      "Epoch 14/20\n",
      "1487/1487 [==============================] - 180s 121ms/step - loss: 1.3455 - accuracy: 0.5905 - val_loss: 1.4966 - val_accuracy: 0.5492\n",
      "Epoch 15/20\n",
      "1487/1487 [==============================] - 179s 120ms/step - loss: 1.3395 - accuracy: 0.5923 - val_loss: 1.4888 - val_accuracy: 0.5579\n",
      "Epoch 16/20\n",
      "1487/1487 [==============================] - 184s 124ms/step - loss: 1.3338 - accuracy: 0.5935 - val_loss: 1.4944 - val_accuracy: 0.5571\n",
      "Epoch 17/20\n",
      "1487/1487 [==============================] - 179s 120ms/step - loss: 1.3299 - accuracy: 0.5931 - val_loss: 1.4804 - val_accuracy: 0.5541\n",
      "Epoch 18/20\n",
      "1487/1487 [==============================] - 183s 123ms/step - loss: 1.3262 - accuracy: 0.5958 - val_loss: 1.4788 - val_accuracy: 0.5618\n",
      "Epoch 19/20\n",
      "1487/1487 [==============================] - 177s 119ms/step - loss: 1.3192 - accuracy: 0.5981 - val_loss: 1.4832 - val_accuracy: 0.5536\n",
      "Epoch 20/20\n",
      "1487/1487 [==============================] - 178s 120ms/step - loss: 1.3168 - accuracy: 0.5979 - val_loss: 1.4807 - val_accuracy: 0.5590\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer= optimizer, metrics=['accuracy'])\n",
    "history = model.fit(X, y, validation_split=0.05, batch_size=128, epochs=20, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRiqN01B4M5X"
   },
   "outputs": [],
   "source": [
    "model.save('keras_model.h5')\n",
    "pickle.dump(history, open(\"history.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQmyURRR4M1z"
   },
   "outputs": [],
   "source": [
    "model = load_model('keras_model.h5')\n",
    "history = pickle.load(open(\"history.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXrEUZsZ4MzS"
   },
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, SEQUENCE_LENGTH, len(chars)))\n",
    "    for t, char in enumerate(text):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "GhHyT7bP4Mwl",
    "outputId": "b9f30ab7-4dcf-488a-8891-7aafdf1fa2b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_input(\"This is an example of input for our LSTM\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPnOnvpI3_ke"
   },
   "outputs": [],
   "source": [
    "# next possible characters\n",
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gik2ItMs5pRP"
   },
   "outputs": [],
   "source": [
    "# predict next character until space\n",
    "def predict_completion(text):\n",
    "    original_text = text\n",
    "    generated = text\n",
    "    completion = ''\n",
    "    while True:\n",
    "        x = prepare_input(text)\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, top_n=1)[0]\n",
    "        next_char = indices_char[next_index]\n",
    "        text = text[1:] + next_char\n",
    "        completion += next_char\n",
    "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
    "            return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g22xVJhK5pOK"
   },
   "outputs": [],
   "source": [
    "def predict_completions(text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msAQ0uhK5pLj"
   },
   "outputs": [],
   "source": [
    "quotes = [\n",
    "    \"It is not a lack of love, but a lack of friendship that makes unhappy marriages.\",\n",
    "    \"That which does not kill us makes us stronger.\",\n",
    "    \"I'm not upset that you lied to me, I'm upset that from now on I can't believe you.\",\n",
    "    \"And those who were seen dancing were thought to be insane by those who could not hear the music.\",\n",
    "    \"It is hard enough to remember my opinions, without also remembering my reasons for them!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "jF1zD-RZ5pIb",
    "outputId": "cc5c7937-7a3b-45a7-c869-f730b2255b98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is not a lack of love, but a lack of \n",
      "['the ', 'a ', 'his ', 'some ', 'interpret ']\n",
      "\n",
      "that which does not kill us makes us str\n",
      "['ongest ', 'ange ', 'ength ', 'ive ', 'uggler ']\n",
      "\n",
      "i'm not upset that you lied to me, i'm u\n",
      "['niversal ', 's ', 'pon ', 'tility ', 'ltimate ']\n",
      "\n",
      "and those who were seen dancing were tho\n",
      "['ugh ', 'se ', 'rought ', 'ots ', 'm ']\n",
      "\n",
      "it is hard enough to remember my opinion\n",
      "[' of ', ', ', '\\nand ', 's ', '. ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in quotes:\n",
    "    seq = q[:40].lower()\n",
    "    print(seq)\n",
    "    print(predict_completions(seq, 5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AoUtNNVX5zQ-"
   },
   "outputs": [],
   "source": [
    "#THANK YOU....."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "keyboard_predictions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
